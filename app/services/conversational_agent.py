"""
æ”¯æŒå¤šè½®å¯¹è¯çš„Agent - é‡æ„ç‰ˆæœ¬
æ”¯æŒåŠ¨æ€é…ç½®å’Œçµæ´»çš„RAG
"""
import json
from typing import List, Dict, Any, Optional
from datetime import datetime
import httpx

from ..agent.tool_base import Tool
from ..services.rag_service import get_rag_service


class ConversationalAgent:
    """
    æ”¯æŒå¤šè½®å¯¹è¯çš„Agentï¼ˆé‡æ„ç‰ˆï¼‰
    
    é‡æ„è¦ç‚¹ï¼š
    1. ä¸å†åœ¨åˆå§‹åŒ–æ—¶å›ºå®šRAGé…ç½®
    2. æ¯æ¬¡è¿è¡Œæ—¶å¯ä»¥åŠ¨æ€æŒ‡å®šæ˜¯å¦ä½¿ç”¨RAGå’Œä½¿ç”¨å“ªä¸ªçŸ¥è¯†åº“
    3. æ”¯æŒæ›´çµæ´»çš„é…ç½®
    
    ç‰¹ç‚¹:
    1. ä¼šè¯å†å²ç®¡ç†
    2. åŠ¨æ€RAGé›†æˆï¼ˆæ¯æ¬¡æ¶ˆæ¯å¯ç‹¬ç«‹é…ç½®ï¼‰
    3. Function Calling
    4. ä¸Šä¸‹æ–‡ä¿æŒ
    """
    
    def __init__(
        self,
        tools: List[Tool],
        llm_config: Dict[str, Any],
        max_iterations: int = 10,
        temperature: float = 0.7,
        verbose: bool = False
    ):
        """
        åˆå§‹åŒ–Agent
        
        Args:
            tools: å¯ç”¨å·¥å…·åˆ—è¡¨
            llm_config: LLMé…ç½®
            max_iterations: æœ€å¤§è¿­ä»£æ¬¡æ•°
            temperature: æ¸©åº¦å‚æ•°
            verbose: æ˜¯å¦æ‰“å°è¯¦ç»†æ—¥å¿—
        """
        self.tools = {tool.name: tool for tool in tools}
        self.llm_config = llm_config
        self.max_iterations = max_iterations
        self.temperature = temperature
        self.verbose = verbose
        self.rag_service = get_rag_service()
    
    def _build_system_prompt(self, rag_context: Optional[str] = None) -> str:
        """æ„å»ºç³»ç»Ÿæç¤ºè¯"""
        tool_descriptions = "\n".join([
            f"- {tool.name}: {tool.description}"
            for tool in self.tools.values()
        ])
        
        base_prompt = f"""ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½åŠ©æ‰‹,å¯ä»¥ä½¿ç”¨ä»¥ä¸‹å·¥å…·æ¥å¸®åŠ©ç”¨æˆ·:

{tool_descriptions}

å·¥ä½œæµç¨‹:
1. ä»”ç»†åˆ†æç”¨æˆ·çš„é—®é¢˜
2. å¦‚æœéœ€è¦å·¥å…·,è°ƒç”¨ç›¸åº”çš„å‡½æ•°
3. æ ¹æ®å·¥å…·è¿”å›çš„ç»“æœç»§ç»­æ¨ç†
4. ç»™å‡ºæ¸…æ™°å‡†ç¡®çš„æœ€ç»ˆç­”æ¡ˆ

æ³¨æ„:
- ä½¿ç”¨å·¥å…·æ—¶è¦å‡†ç¡®ä¼ é€’å‚æ•°
- æ ¹æ®è§‚å¯Ÿç»“æœè°ƒæ•´åç»­è¡ŒåŠ¨
- ä¿æŒå¯¹è¯è¿è´¯,è®°ä½ä¹‹å‰çš„ä¸Šä¸‹æ–‡
"""
        
        # å¦‚æœæœ‰RAGä¸Šä¸‹æ–‡,æ·»åŠ åˆ°ç³»ç»Ÿæç¤ºè¯
        if rag_context:
            base_prompt += f"""

å‚è€ƒçŸ¥è¯†åº“å†…å®¹:
{rag_context}

è¯·ä¼˜å…ˆä½¿ç”¨ä¸Šè¿°çŸ¥è¯†åº“å†…å®¹å›ç­”é—®é¢˜ã€‚å¦‚æœçŸ¥è¯†åº“ä¸­æ²¡æœ‰ç›¸å…³ä¿¡æ¯,å¯ä»¥ä½¿ç”¨å·¥å…·æˆ–åŸºäºä½ çš„çŸ¥è¯†å›ç­”ã€‚"""
        
        return base_prompt
    
    def _get_function_schemas(self) -> List[Dict[str, Any]]:
        """è·å–æ‰€æœ‰å·¥å…·çš„Function Schema"""
        schemas = [tool.to_function_schema() for tool in self.tools.values()]
        
        # æ·»åŠ "å®Œæˆ"å‡½æ•°
        schemas.append({
            "type": "function",
            "function": {
                "name": "finish",
                "description": "å½“ä½ å·²ç»å¾—å‡ºæœ€ç»ˆç­”æ¡ˆæ—¶è°ƒç”¨æ­¤å‡½æ•°",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "answer": {
                            "type": "string",
                            "description": "ç»™ç”¨æˆ·çš„æœ€ç»ˆç­”æ¡ˆ"
                        }
                    },
                    "required": ["answer"]
                }
            }
        })
        
        return schemas
    
    async def _call_llm(
        self,
        messages: List[Dict[str, Any]],
        functions: List[Dict[str, Any]]
    ) -> Dict[str, Any]:
        """è°ƒç”¨LLM"""
        api_key = self.llm_config.get("api_key")
        base_url = self.llm_config.get("base_url")
        model = self.llm_config.get("model", "deepseek-chat")
        
        payload = {
            "model": model,
            "messages": messages,
            "tools": functions,
            "tool_choice": "auto",
            "temperature": self.temperature
        }
        
        async with httpx.AsyncClient(timeout=60.0) as client:
            response = await client.post(
                base_url,
                headers={
                    "Authorization": f"Bearer {api_key}",
                    "Content-Type": "application/json"
                },
                json=payload
            )
            
            if response.status_code != 200:
                raise Exception(f"LLMè°ƒç”¨å¤±è´¥: {response.text}")
            
            return response.json()
    
    async def _execute_tool(
        self,
        tool_name: str,
        tool_input: Dict[str, Any]
    ) -> str:
        """æ‰§è¡Œå·¥å…·"""
        if tool_name not in self.tools:
            return json.dumps({
                "success": False,
                "error": f"å·¥å…· '{tool_name}' ä¸å­˜åœ¨"
            }, ensure_ascii=False)
        
        tool = self.tools[tool_name]
        result = await tool.run(**tool_input)
        
        return json.dumps({
            "success": result.success,
            "result": result.result if result.success else None,
            "error": result.error if not result.success else None
        }, ensure_ascii=False)
    
    async def _get_rag_context(
        self,
        query: str,
        kb_name: str,
        top_k: int = 3
    ) -> Optional[Dict[str, Any]]:
        """
        è·å–RAGä¸Šä¸‹æ–‡ï¼ˆé‡æ„ç‰ˆï¼‰
        
        Args:
            query: æŸ¥è¯¢æ–‡æœ¬
            kb_name: çŸ¥è¯†åº“åç§°
            top_k: è¿”å›æ–‡æ¡£æ•°é‡
            
        Returns:
            RAGç»“æœ
        """
        try:
            result = self.rag_service.rag_query(
                kb_name=kb_name,
                query=query,
                top_k=top_k
            )
            return result
        except Exception as e:
            if self.verbose:
                print(f"RAGæ£€ç´¢å¤±è´¥: {str(e)}")
            return None
    
    async def run(
        self,
        user_message: str,
        conversation_history: List[Dict[str, Any]],
        # æ–°å¢ï¼šåŠ¨æ€RAGé…ç½®
        enable_rag: bool = False,
        kb_name: Optional[str] = None,
        rag_top_k: int = 3
    ) -> Dict[str, Any]:
        """
        è¿è¡ŒAgentå¤„ç†ç”¨æˆ·æ¶ˆæ¯ï¼ˆé‡æ„ç‰ˆï¼‰
        
        Args:
            user_message: ç”¨æˆ·æ¶ˆæ¯
            conversation_history: ä¼šè¯å†å²
            enable_rag: æ˜¯å¦å¯ç”¨RAGï¼ˆåŠ¨æ€æŒ‡å®šï¼‰
            kb_name: çŸ¥è¯†åº“åç§°ï¼ˆåŠ¨æ€æŒ‡å®šï¼‰
            rag_top_k: RAGæ£€ç´¢æ•°é‡
            
        Returns:
            æ‰§è¡Œç»“æœ
        """
        start_time = datetime.now()
        steps = []
        
        # 1. å¦‚æœå¯ç”¨RAG,æ£€ç´¢ç›¸å…³å†…å®¹
        rag_context = None
        source_documents = []
        
        if enable_rag and kb_name:
            rag_result = await self._get_rag_context(user_message, kb_name, rag_top_k)
            if rag_result:
                rag_context = rag_result.get("context", "")
                source_documents = rag_result.get("source_documents", [])
                
                if self.verbose:
                    print(f"\nğŸ“š RAGæ£€ç´¢åˆ° {len(source_documents)} æ¡ç›¸å…³æ–‡æ¡£")
                    print(f"çŸ¥è¯†åº“: {kb_name}")
        
        # 2. æ„å»ºæ¶ˆæ¯åˆ—è¡¨
        messages = []
        
        # æ·»åŠ ç³»ç»Ÿæç¤ºè¯
        system_prompt = self._build_system_prompt(rag_context)
        messages.append({
            "role": "system",
            "content": system_prompt
        })
        
        # æ·»åŠ å†å²æ¶ˆæ¯
        messages.extend(conversation_history)
        
        # æ·»åŠ å½“å‰ç”¨æˆ·æ¶ˆæ¯
        messages.append({
            "role": "user",
            "content": user_message
        })
        
        # 3. è·å–å¯ç”¨å‡½æ•°
        functions = self._get_function_schemas()
        
        iteration = 0
        
        if self.verbose:
            print(f"\n{'='*60}")
            print(f"Agentå¼€å§‹å¤„ç†: {user_message}")
            if enable_rag:
                print(f"RAGæ¨¡å¼: å¯ç”¨ (çŸ¥è¯†åº“: {kb_name})")
            print(f"{'='*60}\n")
        
        try:
            while iteration < self.max_iterations:
                iteration += 1
                
                if self.verbose:
                    print(f"--- è¿­ä»£ {iteration} ---")
                
                # è°ƒç”¨LLM
                response = await self._call_llm(messages, functions)
                assistant_message = response["choices"][0]["message"]
                
                # æ£€æŸ¥æ˜¯å¦æœ‰å·¥å…·è°ƒç”¨
                if assistant_message.get("tool_calls"):
                    
                    # å…³é”®ä¿®æ”¹ï¼šé¦–å…ˆå°†LLMçš„å›å¤ï¼ˆåŒ…å«æ‰€æœ‰å·¥å…·è°ƒç”¨è¯·æ±‚ï¼‰æ·»åŠ åˆ°å†å²
                    messages.append(assistant_message)
                    
                    # å…³é”®ä¿®æ”¹ï¼šéå†æ‰€æœ‰å·¥å…·è°ƒç”¨
                    tool_calls = assistant_message["tool_calls"]
                    
                    for tool_call in tool_calls:
                        function_name = tool_call["function"]["name"]
                        function_args = json.loads(tool_call["function"]["arguments"])
                        
                        if self.verbose:
                            print(f"ğŸ”§ è°ƒç”¨å·¥å…·: {function_name}")
                            print(f"å‚æ•°: {function_args}")
                        
                        # è®°å½•æ­¥éª¤
                        steps.append({
                            "iteration": iteration,
                            "action": function_name,
                            "input": function_args,
                            "timestamp": datetime.now().isoformat()
                        })
                        
                        # æ£€æŸ¥æ˜¯å¦æ˜¯ç»“æŸå‡½æ•°
                        if function_name == "finish":
                            final_answer = function_args.get("answer", "")
                            
                            if self.verbose:
                                print(f"âœ… æœ€ç»ˆç­”æ¡ˆ: {final_answer}\n")
                            
                            # æ³¨æ„ï¼šä¸€æ—¦é‡åˆ° finishï¼Œç«‹å³è¿”å›
                            return {
                                "success": True,
                                "answer": final_answer,
                                "steps": steps,
                                "iterations": iteration,
                                "execution_time": (datetime.now() - start_time).total_seconds(),
                                "rag_enabled": enable_rag,
                                "rag_kb_name": kb_name if enable_rag else None,
                                "source_documents": source_documents if enable_rag else [],
                                "messages_to_save": [
                                    {"role": "assistant", "content": final_answer}
                                ]
                            }
                        
                        # æ‰§è¡Œå·¥å…·
                        observation = await self._execute_tool(function_name, function_args)
                        
                        if self.verbose:
                            print(f"ğŸ“ è§‚å¯Ÿ: {observation}\n")
                        
                        # å‡è®¾ steps åˆ—è¡¨æ˜¯æŒ‰é¡ºåºæ·»åŠ çš„ï¼Œå–æœ€åä¸€ä¸ª
                        if steps:
                            steps[-1]["observation"] = observation
                        
                        # å…³é”®ä¿®æ”¹ï¼šå°† *å½“å‰å·¥å…·* çš„ç»“æœæ·»åŠ åˆ°æ¶ˆæ¯å†å²
                        messages.append({
                            "role": "tool",
                            "tool_call_id": tool_call["id"],
                            "content": observation
                        })
                        
                    # å¾ªç¯ç»“æŸåï¼Œè¿›å…¥ä¸‹ä¸€æ¬¡è¿­ä»£

                else:
                    # LLMç›´æ¥å›ç­”
                    answer = assistant_message.get("content", "")
                    
                    if self.verbose:
                        print(f"âœ… ç›´æ¥å›ç­”: {answer}\n")
                    
                    return {
                        "success": True,
                        "answer": answer,
                        "steps": steps,
                        "iterations": iteration,
                        "execution_time": (datetime.now() - start_time).total_seconds(),
                        "rag_enabled": enable_rag,
                        "rag_kb_name": kb_name if enable_rag else None,
                        "source_documents": source_documents if enable_rag else [],
                        "messages_to_save": [
                            {"role": "assistant", "content": answer}
                        ]
                    }
            
            # è¾¾åˆ°æœ€å¤§è¿­ä»£æ¬¡æ•°
            return {
                "success": False,
                "answer": "æŠ±æ­‰,æˆ‘åœ¨è§„å®šçš„æ­¥éª¤å†…æœªèƒ½å¾—å‡ºç­”æ¡ˆ",
                "steps": steps,
                "iterations": iteration,
                "execution_time": (datetime.now() - start_time).total_seconds(),
                "error": "è¾¾åˆ°æœ€å¤§è¿­ä»£æ¬¡æ•°",
                "rag_enabled": enable_rag,
                "rag_kb_name": kb_name if enable_rag else None,
                "source_documents": source_documents if enable_rag else []
            }
            
        except Exception as e:
            return {
                "success": False,
                "answer": f"æ‰§è¡Œè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}",
                "steps": steps,
                "iterations": iteration,
                "execution_time": (datetime.now() - start_time).total_seconds(),
                "error": str(e),
                "rag_enabled": enable_rag,
                "rag_kb_name": kb_name if enable_rag else None,
                "source_documents": source_documents if enable_rag else []
            }